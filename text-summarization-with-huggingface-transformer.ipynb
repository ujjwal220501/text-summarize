{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T02:40:28.024048Z",
     "iopub.status.busy": "2024-11-26T02:40:28.023659Z",
     "iopub.status.idle": "2024-11-26T02:40:28.028687Z",
     "shell.execute_reply": "2024-11-26T02:40:28.027748Z",
     "shell.execute_reply.started": "2024-11-26T02:40:28.024010Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-26T06:32:01.700835Z",
     "iopub.status.busy": "2024-11-26T06:32:01.700142Z",
     "iopub.status.idle": "2024-11-26T06:32:01.705944Z",
     "shell.execute_reply": "2024-11-26T06:32:01.704992Z",
     "shell.execute_reply.started": "2024-11-26T06:32:01.700798Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T06:32:04.790106Z",
     "iopub.status.busy": "2024-11-26T06:32:04.789531Z",
     "iopub.status.idle": "2024-11-26T06:32:04.982136Z",
     "shell.execute_reply": "2024-11-26T06:32:04.981196Z",
     "shell.execute_reply.started": "2024-11-26T06:32:04.790069Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13818513</td>\n",
       "      <td>Amanda: I baked  cookies. Do you want some?\\r\\...</td>\n",
       "      <td>Amanda baked cookies and will bring Jerry some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13728867</td>\n",
       "      <td>Olivia: Who are you voting for in this electio...</td>\n",
       "      <td>Olivia and Olivier are voting for liberals in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13681000</td>\n",
       "      <td>Tim: Hi, what's up?\\r\\nKim: Bad mood tbh, I wa...</td>\n",
       "      <td>Kim may try the pomodoro technique recommended...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13730747</td>\n",
       "      <td>Edward: Rachel, I think I'm in ove with Bella....</td>\n",
       "      <td>Edward thinks he is in love with Bella. Rachel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13728094</td>\n",
       "      <td>Sam: hey  overheard rick say something\\r\\nSam:...</td>\n",
       "      <td>Sam is confused, because he overheard Rick com...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           dialogue  \\\n",
       "0  13818513  Amanda: I baked  cookies. Do you want some?\\r\\...   \n",
       "1  13728867  Olivia: Who are you voting for in this electio...   \n",
       "2  13681000  Tim: Hi, what's up?\\r\\nKim: Bad mood tbh, I wa...   \n",
       "3  13730747  Edward: Rachel, I think I'm in ove with Bella....   \n",
       "4  13728094  Sam: hey  overheard rick say something\\r\\nSam:...   \n",
       "\n",
       "                                             summary  \n",
       "0  Amanda baked cookies and will bring Jerry some...  \n",
       "1  Olivia and Olivier are voting for liberals in ...  \n",
       "2  Kim may try the pomodoro technique recommended...  \n",
       "3  Edward thinks he is in love with Bella. Rachel...  \n",
       "4  Sam is confused, because he overheard Rick com...  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset (example, adjust path as needed)\n",
    "train_data = pd.read_csv(\"/kaggle/input/samsum-dataset-text-summarization/samsum-train.csv\")\n",
    "validation_data = pd.read_csv(\"/kaggle/input/samsum-dataset-text-summarization/samsum-validation.csv\")\n",
    "\n",
    "# Display a sample\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T06:32:23.597565Z",
     "iopub.status.busy": "2024-11-26T06:32:23.596769Z",
     "iopub.status.idle": "2024-11-26T06:32:23.608472Z",
     "shell.execute_reply": "2024-11-26T06:32:23.607439Z",
     "shell.execute_reply.started": "2024-11-26T06:32:23.597520Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_data = train_data.sample(n=4000,random_state=42).reset_index(drop=True)\n",
    "validation_data = validation_data.sample(n=500, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T06:32:26.251698Z",
     "iopub.status.busy": "2024-11-26T06:32:26.251383Z",
     "iopub.status.idle": "2024-11-26T06:32:26.463913Z",
     "shell.execute_reply": "2024-11-26T06:32:26.463171Z",
     "shell.execute_reply.started": "2024-11-26T06:32:26.251671Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13811908</td>\n",
       "      <td>violet: hi! i came across this austin's articl...</td>\n",
       "      <td>violet sent claire austin's article.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13716431</td>\n",
       "      <td>pat: so does anyone know when the stream is go...</td>\n",
       "      <td>pat and lou are waiting for the stream but kev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13810214</td>\n",
       "      <td>jane:  jane: whaddya think? shona: this ur tin...</td>\n",
       "      <td>jane is updating her tinder profile tonight an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13729823</td>\n",
       "      <td>adam: do u have a map of paris? tom: yes, why?...</td>\n",
       "      <td>tom has a map of paris.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13681400</td>\n",
       "      <td>frank: hi, how's the family? mike: great! sam'...</td>\n",
       "      <td>mike is happy, because sam's moved out. mike a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>13681041</td>\n",
       "      <td>barry: hello buddy michael: hey barry: do you ...</td>\n",
       "      <td>barry and michael will watch football instead ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>13818705</td>\n",
       "      <td>karen: hey lisa. larissa and me have recently ...</td>\n",
       "      <td>karen and larissa moved to belgium and ask lis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>13821859</td>\n",
       "      <td>miles: hey, guys, i'm so sorry, but i missed t...</td>\n",
       "      <td>miles has missed the bus, so he may be 15 minu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>13812716</td>\n",
       "      <td>emma: did you finish the book i gave you? liam...</td>\n",
       "      <td>emma gave \"the first fifteen lives of harry au...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>13717021</td>\n",
       "      <td>jenna: dudes, were we supposed to read the who...</td>\n",
       "      <td>jenna, hannah and denis should read 40 pages f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                           dialogue  \\\n",
       "0     13811908  violet: hi! i came across this austin's articl...   \n",
       "1     13716431  pat: so does anyone know when the stream is go...   \n",
       "2     13810214  jane:  jane: whaddya think? shona: this ur tin...   \n",
       "3     13729823  adam: do u have a map of paris? tom: yes, why?...   \n",
       "4     13681400  frank: hi, how's the family? mike: great! sam'...   \n",
       "...        ...                                                ...   \n",
       "3995  13681041  barry: hello buddy michael: hey barry: do you ...   \n",
       "3996  13818705  karen: hey lisa. larissa and me have recently ...   \n",
       "3997  13821859  miles: hey, guys, i'm so sorry, but i missed t...   \n",
       "3998  13812716  emma: did you finish the book i gave you? liam...   \n",
       "3999  13717021  jenna: dudes, were we supposed to read the who...   \n",
       "\n",
       "                                                summary  \n",
       "0                  violet sent claire austin's article.  \n",
       "1     pat and lou are waiting for the stream but kev...  \n",
       "2     jane is updating her tinder profile tonight an...  \n",
       "3                               tom has a map of paris.  \n",
       "4     mike is happy, because sam's moved out. mike a...  \n",
       "...                                                 ...  \n",
       "3995  barry and michael will watch football instead ...  \n",
       "3996  karen and larissa moved to belgium and ask lis...  \n",
       "3997  miles has missed the bus, so he may be 15 minu...  \n",
       "3998  emma gave \"the first fifteen lives of harry au...  \n",
       "3999  jenna, hannah and denis should read 40 pages f...  \n",
       "\n",
       "[4000 rows x 3 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean the text by removing unwanted characters\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\r\\n', ' ', text)  # Remove carriage returns and line breaks\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "    text = re.sub(r'<.*?>', '', text)  # Remove any XML tags\n",
    "    text = text.strip().lower()  # Strip and convert to lower case\n",
    "    return text\n",
    "\n",
    "# Apply cleaning to dialogue and summary columns\n",
    "train_data['dialogue'] = train_data['dialogue'].apply(clean_text)\n",
    "train_data['summary'] = train_data['summary'].apply(clean_text)\n",
    "\n",
    "validation_data['dialogue'] = validation_data['dialogue'].apply(clean_text)\n",
    "validation_data['summary'] = validation_data['summary'].apply(clean_text)\n",
    "\n",
    "\n",
    "# Display a sample after cleaning\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T06:32:29.745015Z",
     "iopub.status.busy": "2024-11-26T06:32:29.744698Z",
     "iopub.status.idle": "2024-11-26T06:32:32.579852Z",
     "shell.execute_reply": "2024-11-26T06:32:32.578971Z",
     "shell.execute_reply.started": "2024-11-26T06:32:29.744989Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1224, 103)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_max_len = max(len(tokenizer.encode(text)) for text in train_data['dialogue'])\n",
    "output_max_len = max(len(tokenizer.encode(text)) for text in train_data['summary'])\n",
    "\n",
    "input_max_len, output_max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T06:32:49.501459Z",
     "iopub.status.busy": "2024-11-26T06:32:49.500800Z",
     "iopub.status.idle": "2024-11-26T06:32:49.952558Z",
     "shell.execute_reply": "2024-11-26T06:32:49.951851Z",
     "shell.execute_reply.started": "2024-11-26T06:32:49.501425Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T06:32:53.752722Z",
     "iopub.status.busy": "2024-11-26T06:32:53.751920Z",
     "iopub.status.idle": "2024-11-26T06:32:57.533102Z",
     "shell.execute_reply": "2024-11-26T06:32:57.532071Z",
     "shell.execute_reply.started": "2024-11-26T06:32:53.752686Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Preprocessing function for tokenization\n",
    "def preprocess_function(examples):\n",
    "    # Tokenize the dialogue and summary\n",
    "    inputs = tokenizer(examples[\"dialogue\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "    targets = tokenizer(examples[\"summary\"], padding=\"max_length\", truncation=True, max_length=150)\n",
    "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
    "    return inputs\n",
    "\n",
    "# Apply the preprocessing\n",
    "train_dataset = train_data.apply(preprocess_function, axis=1)\n",
    "val_dataset = validation_data.apply(preprocess_function, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T06:32:57.534836Z",
     "iopub.status.busy": "2024-11-26T06:32:57.534535Z",
     "iopub.status.idle": "2024-11-26T06:32:57.542096Z",
     "shell.execute_reply": "2024-11-26T06:32:57.541190Z",
     "shell.execute_reply.started": "2024-11-26T06:32:57.534807Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [25208, 10, 7102, 55, 3, 23, 764, 640, 48, 403, 17, 77, 31, 7, 1108, 11, 3, 23, 816, 24, 25, 429, 253, 34, 1477, 25208, 10, 3, 7997, 15, 10, 7102, 55, 3, 10, 61, 2049, 6, 68, 3, 23, 31, 162, 641, 608, 34, 5, 3, 10, 61, 3, 7997, 15, 10, 68, 2049, 21, 1631, 81, 140, 3, 10, 61, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [25208, 1622, 3, 7997, 15, 403, 17, 77, 31, 7, 1108, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T06:34:11.921989Z",
     "iopub.status.busy": "2024-11-26T06:34:11.921290Z",
     "iopub.status.idle": "2024-11-26T06:45:50.625360Z",
     "shell.execute_reply": "2024-11-26T06:45:50.624561Z",
     "shell.execute_reply.started": "2024-11-26T06:34:11.921958Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3000/3000 11:36, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.424600</td>\n",
       "      <td>0.380310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.378400</td>\n",
       "      <td>0.359477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.371100</td>\n",
       "      <td>0.354424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.363100</td>\n",
       "      <td>0.349908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.348632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.353400</td>\n",
       "      <td>0.348830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3000, training_loss=0.9062748317718505, metrics={'train_runtime': 696.9865, 'train_samples_per_second': 34.434, 'train_steps_per_second': 4.304, 'total_flos': 3248203235328000.0, 'train_loss': 0.9062748317718505, 'epoch': 6.0})"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",          # output directory for checkpoints\n",
    "    num_train_epochs=6,              # number of training epochs\n",
    "    per_device_train_batch_size=8,   # batch size per device during training\n",
    "    per_device_eval_batch_size=8,    # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir=\"./logs\",            # directory for storing logs\n",
    "    logging_steps=50,                # how often to log training info\n",
    "    save_steps=500,                  # how often to save a model checkpoint\n",
    "    eval_steps=50,                   # how often to run evaluation\n",
    "    evaluation_strategy=\"epoch\",     # Ensure evaluation happens every `epoch`\n",
    ")\n",
    "\n",
    "# Trainer setup\n",
    "trainer = Trainer(\n",
    "    model=model, \n",
    "    args=training_args, \n",
    "    train_dataset=train_dataset, \n",
    "    eval_dataset=val_dataset\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T06:45:56.647829Z",
     "iopub.status.busy": "2024-11-26T06:45:56.646884Z",
     "iopub.status.idle": "2024-11-26T06:45:57.070206Z",
     "shell.execute_reply": "2024-11-26T06:45:57.069290Z",
     "shell.execute_reply.started": "2024-11-26T06:45:56.647790Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./saved_summary_model/tokenizer_config.json',\n",
       " './saved_summary_model/special_tokens_map.json',\n",
       " './saved_summary_model/spiece.model',\n",
       " './saved_summary_model/added_tokens.json')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the fine-tuned model\n",
    "model.save_pretrained(\"./saved_summary_model\")\n",
    "tokenizer.save_pretrained(\"./saved_summary_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T06:46:00.498563Z",
     "iopub.status.busy": "2024-11-26T06:46:00.498185Z",
     "iopub.status.idle": "2024-11-26T06:46:00.941780Z",
     "shell.execute_reply": "2024-11-26T06:46:00.940749Z",
     "shell.execute_reply.started": "2024-11-26T06:46:00.498529Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load the saved model and tokenizer\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"./saved_summary_model\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"./saved_summary_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarization System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T06:47:46.044719Z",
     "iopub.status.busy": "2024-11-26T06:47:46.044372Z",
     "iopub.status.idle": "2024-11-26T06:47:46.052021Z",
     "shell.execute_reply": "2024-11-26T06:47:46.051176Z",
     "shell.execute_reply.started": "2024-11-26T06:47:46.044690Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Ensure the model is on the correct device (GPU if available)\n",
    "device = model.device  # Get the device the model is on\n",
    "\n",
    "def summarize_dialogue(dialogue):\n",
    "    dialogue = clean_text(dialogue)  # Assuming clean_text is defined\n",
    "    inputs = tokenizer(dialogue, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512)\n",
    "    \n",
    "    # Move input tensors to the same device as the model\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "    # Generate summary\n",
    "    outputs = model.generate(\n",
    "        inputs[\"input_ids\"], \n",
    "        max_length=150,  \n",
    "        num_beams=4, \n",
    "        early_stopping=True\n",
    "    )\n",
    "    \n",
    "    # Decode the generated summary\n",
    "    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T06:47:47.257634Z",
     "iopub.status.busy": "2024-11-26T06:47:47.256599Z",
     "iopub.status.idle": "2024-11-26T06:47:48.837618Z",
     "shell.execute_reply": "2024-11-26T06:47:48.836927Z",
     "shell.execute_reply.started": "2024-11-26T06:47:47.257598Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: claire was reading an article about austin and thought she might find it interesting. violet has already read that one last week.\n"
     ]
    }
   ],
   "source": [
    "# Test with a sample input\n",
    "sample_dialogue = \"\"\"\n",
    "Violet: Hey Claire! I was reading an article about Austin and thought you might find it interesting! \n",
    "Violet: It's about the current trends in urban development and how cities are planning for the future.\n",
    "Violet: Here, let me share the link: <file_other>\n",
    "Claire: Oh wow, that sounds like an insightful read. But I've actually already read that one last week. \n",
    "Claire: It was really interesting though, especially the part about sustainable architecture in cities. \n",
    "Claire: You know, I've been following these urban planning discussions for a while now.\n",
    "Violet: Oh, I didn’t know that! Well, I’ll look for something else then, maybe something about eco-friendly cities or tech innovations.\n",
    "Claire: That would be awesome! Let me know if you find something cool.\n",
    "Violet: Sure, I’ll keep you posted. Thanks for the feedback!\n",
    "\"\"\"\n",
    "\n",
    "summary = summarize_dialogue(sample_dialogue)\n",
    "print(\"Summary:\", summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T06:48:16.574945Z",
     "iopub.status.busy": "2024-11-26T06:48:16.574173Z",
     "iopub.status.idle": "2024-11-26T06:48:19.090220Z",
     "shell.execute_reply": "2024-11-26T06:48:19.089359Z",
     "shell.execute_reply.started": "2024-11-26T06:48:16.574911Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: sarah has seen the latest tech gadget reviews. john found this smartwatch that's supposed to have amazing health tracking features. there are also new smartphones coming out with even better cameras and longer battery life.\n"
     ]
    }
   ],
   "source": [
    "# Test with a dialogue on a different topic\n",
    "sample_dialogue = \"\"\"\n",
    "John: Hey Sarah, have you seen the latest tech gadget reviews? I found this new smartwatch that's supposed to have amazing health tracking features.\n",
    "John: It tracks heart rate, blood oxygen levels, sleep patterns, and even stress levels! It sounds like something right up your alley. \n",
    "Sarah: That sounds really interesting! But I’ve been trying to cut down on tech distractions. I’ve heard these devices can be really overwhelming sometimes.\n",
    "Sarah: I do think it’s cool that they can track so many health metrics though. I’m curious how accurate they really are.\n",
    "John: Yeah, me too! There are also some new smartphones coming out with even better cameras and longer battery life. The new flagship model from XYZ brand has some insane specs.\n",
    "Sarah: Ooh, I haven’t kept up with phones recently, but I’ve heard the camera quality is getting ridiculously good. It’s almost like a professional camera in your pocket now!\n",
    "Sarah: Still, I feel like I’m fine with my current phone for now. I don’t really feel the need to upgrade unless something really groundbreaking comes out.\n",
    "John: Totally understand that. It’s the same with me. But I think the battery life improvements are enough to make me consider it. I hate running out of battery when I’m out and about.\n",
    "Sarah: That’s fair! I’m always worried about battery life too. Honestly, I think phones should last at least two full days on a single charge by now.\n",
    "John: I agree! It’s so annoying when your phone dies in the middle of the day. I wonder if we’ll ever get to a point where we don’t have to charge our phones every day.\n",
    "Sarah: That would be amazing! I think as tech improves, battery tech might also catch up. Let’s hope the next generation of phones can last longer!\n",
    "\"\"\"\n",
    "\n",
    "summary = summarize_dialogue(sample_dialogue)\n",
    "print(\"Summary:\", summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T06:48:27.120420Z",
     "iopub.status.busy": "2024-11-26T06:48:27.120039Z",
     "iopub.status.idle": "2024-11-26T06:48:29.277593Z",
     "shell.execute_reply": "2024-11-26T06:48:29.276665Z",
     "shell.execute_reply.started": "2024-11-26T06:48:27.120389Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: the latest climate change report reveals alarming global temperature rises. the earth’s temperature is on track to rise by 1.5°c within the next two decades. experts urges governments to set stronger policies, but individuals can help by reducing waste, conserving water, and supporting green initiatives.\n"
     ]
    }
   ],
   "source": [
    "# Test with a dialogue on a current news topic\n",
    "sample_dialogue = \"\"\"\n",
    "Reporter: In today's news, the latest climate change report reveals alarming global temperature rises. According to the Intergovernmental Panel on Climate Change (IPCC), the Earth’s temperature is on track to rise by 1.5°C within the next two decades.\n",
    "Reporter: This is expected to lead to more frequent and severe heatwaves, flooding, and extreme weather events. Coastal cities are at particular risk due to rising sea levels.\n",
    "Expert: The report emphasizes that immediate action is needed to prevent catastrophic consequences. We need to significantly reduce carbon emissions and transition to renewable energy sources.\n",
    "Expert: If global temperatures increase by more than 1.5°C, we could face irreversible damage to ecosystems, agriculture, and water supply. It will have a devastating impact on biodiversity as well.\n",
    "Reporter: The IPCC also stresses the importance of individual action. Governments must set stronger policies, but individuals can help by reducing waste, conserving water, and supporting green initiatives.\n",
    "Expert: It's not just about the big changes; small actions like using public transportation, reducing meat consumption, and recycling can collectively make a significant difference.\n",
    "Reporter: With the next UN Climate Summit coming up next month, world leaders will need to prioritize climate action. The stakes have never been higher for our planet’s future.\n",
    "\"\"\"\n",
    "\n",
    "summary = summarize_dialogue(sample_dialogue)\n",
    "print(\"Summary:\", summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Mode To Your Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T06:48:41.330059Z",
     "iopub.status.busy": "2024-11-26T06:48:41.329176Z",
     "iopub.status.idle": "2024-11-26T06:48:54.302706Z",
     "shell.execute_reply": "2024-11-26T06:48:54.301797Z",
     "shell.execute_reply.started": "2024-11-26T06:48:41.330010Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/saved_summary_model.zip'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Path to the directory containing the fine-tuned model\n",
    "model_dir = \"./saved_summary_model\"\n",
    "\n",
    "# Output zip file path\n",
    "output_zip_path = \"saved_summary_model.zip\"\n",
    "\n",
    "# Create a zip archive\n",
    "shutil.make_archive(base_name=\"saved_summary_model\", format=\"zip\", root_dir=model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T06:48:54.304276Z",
     "iopub.status.busy": "2024-11-26T06:48:54.303998Z",
     "iopub.status.idle": "2024-11-26T06:48:54.310423Z",
     "shell.execute_reply": "2024-11-26T06:48:54.309679Z",
     "shell.execute_reply.started": "2024-11-26T06:48:54.304243Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='saved_summary_model.zip' target='_blank'>saved_summary_model.zip</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/saved_summary_model.zip"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "\n",
    "# Display a download link\n",
    "FileLink(output_zip_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 3438844,
     "sourceId": 6004344,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
